$LastChangedDate: 2012-02-14 01:37:21 -0500 (Tue, 14 Feb 2012) $
$LastChangedRevision: 389 $
$LastChangedBy: ivan $


** POLYPHEN-2 USAGE

In the examples below, all command lines start with a "$" symbol,
which indicates Bash shell command-line prompt: the "$" symbols
should be omitted when entering commands into your shell.

NOTE: "$PPH" indicates your PolyPhen-2 installation directory.

PolyPhen-2 analysis pipeline consists of three separate components,
each one executed by a dedicated Perl program:

  * MapSNPs     (mapsnps.pl)   Genomic SNP annotation tool
  * PolyPhen-2  (run_pph.pl)   Protein variant annotation tool
  * PolyPhen-2  (run_weka.pl)  Probabilistic variant classifier

To get help with each program's options and arguments, execute the
script without arguments; to get extended help, as well as the input
format description, add "-h" option, e.g.:

  $ $PPH/bin/mapsnps.pl -h
  $ $PPH/bin/run_pph.pl -h
  $ $PPH/bin/run_weka.pl -h


* MapSNPs (mapsnps.pl) is an optional tool which can be used when you
have a list of chromosome positions and allele nucleotides as input.
PolyPhen-2 main module (run_pph.pl) requires protein substitutions
as its input, so MapSNPs will perform the conversion.

MapSNPs maps genomic SNPs to human genes using UCSC hg19 human genome
assembly and knownGene set of transcripts, reports all missense
variants found, fetches UniProtKB/Swiss-Prot protein entry with
a sequence matching that of the transcript's CDS, and outputs
a list of corresponding amino acid residue substitutions in the
UniProtKB protein in a format accepted by the next pipeline
step (run_pph.pl).

MapSNPs has some limitations: it only works with single nucleotide
variants, neither insertions/deletions nor other multinucleotide
sequence changes are supported; it can only annotate biallelic
variants -- if you specify several alternative nucleotides as
alleles each one in turn will be paired with reference nucleotide and
analyzed as a separate biallelic variant. MapSNPs only works with
the human genome assembly (but both hg19 and hg18 are supported).

Example of a typical mapsnps.pl command line:

  $ $PPH/bin/mapsnps.pl -g hg19 -m -U -y subs.pph.input snps.list 1>snps.features 2>mapsnps.log &

Where:

  snps.list       input text file with chromosome coordinates
                  and allele nucleotides prepared by a user

  subs.pph.input  output file with the protein substitution
                  specifications in run_pph.pl input format

  snps.features   output file with detailed functional
                  annotations of the SNPs in user input

  mapsnps.log     log file with program's errors and warnings

You can find complete description of mapsnps.pl functional annotations
("snps.features" file in the example above) at the following link:

  http://genetics.bwh.harvard.edu/pph2/dokuwiki/appendix_b


* PolyPhen-2 protein annotation tool (run_pph.pl) extracts protein
annotations from various sequence and structural databases and
calculates several evolutionary conservation scores from multiple
sequence alignments (building MSA in the process if it is not already
present). The output of run_pph.pl program is only an intermediate step
in the analysis pipeline and is NOT intended to be directly interpreted
by a user. The reason for this separate step is that it wraps up most
computationally-intensive operations in a single program and allows
to run it on a distributed parallel HPC system for maximum performance.
See below for description of built-in support for Grid Engine and
Platform LSF parallel execution environments.

Example of a typical run_pph.pl command line:

  $ $PPH/bin/run_pph.pl subs.pph.input 1>pph.features 2>run_pph.log &

Where:

  subs.pph.input  input text file with the protein substitution
                  specifications, either prepared by a user or
                  generated by mapsnps.pl program

  pph.features    output file with detailed functional
                  annotations of the SNPs in user input

  run_pph.log     log file with program's errors and warnings


* PolyPhen-2 probabilistic classification tool (run_weka.pl) takes
annotations, conservation scores and other features generated by
run_pph.pl and produces, for each variant input, a qualitative
prediction outcome ("benign", "possibly damaging", "probably damaging")
and a probability score for the variant to have damaging effect on the
protein function. Several prediction confidence scores are also output:
model sensitivity, specificity, and false discovery rate at the
particular probability threshold level.

Example of a typical run_weka.pl command line:

  $ $PPH/bin/run_weka.pl pph.features 1>pph.predictions

Where:

  pph.features    input file with SNPs functional annotations
                  produced by run_pph.pl program

  pph.predictions output file with predictions and scores

Add the following option to the command line above to utilize HumVar
instead of the default HumDiv model for predictions:

  -l $PPH/models/HumVar.UniRef100.NBd.f11.model

Note: run_weka.pl is fairly fast and should not produce any warnings,
hence, normally, there is no need to run it in the background.

You can find complete description of run_weka.pl output at the
following link:

  http://genetics.bwh.harvard.edu/pph2/dokuwiki/appendix_a

Most likely, you will be interested in "prediction" and "pph2_prob"
columns contents; the rest of annotations are only useful if you
want to investigate some of the supporting features in detail.


* Complete pipeline work flow:

[ (SNPs) >> mapsnps.pl ] >>  (Substitutions) >> run_pph.pl >> run_weka.pl >> (Predictions)

Note: There is "pph" wrapper script available, combining run_pph.pl
and run_weka.pl program calls in single command; it can be used for
analyzing small batches of protein variants:

  $ $PPH/bin/pph subs.pph.input >pph.predictions

"pph" script utilizes default HumDiv classifier but provides almost no
diagnostics in case of errors. Its use is discouraged due to limited
functionality.


** POLYPHEN-2 ADVANCED CONFIGURATION OPTIONS


* Storing large databases outside main installation tree

It is often convenient to keep the databases and large datasets
PolyPhen-2 uses in a separate location (or locations) outside
rest of the PolyPhen-2 files, e.g., on a dedicated file server.
This can be achieved by moving selected subdirectories from the
installation tree and editing corresponding lines in
$PPH/config/databases.cnf configuration file to point to the new
locations. Follow comments inside the databases.cnf file for
exact format of each database path configuration option.

Here is the full list of variables that can be reconfigured
(original PolyPhen-2 installation subdirectories for the corresponding
databases are given in brackets):

NRDB_BLAST  (nrdb)    Non-redundant protein sequence database (UniRef100)
UNIPROT     (uniprot) UniProtKB protein sequences and annotations
PDB         (wwpdb)   RCSB PDB structures
DSSP        (dssp)    DSSP structural database
GOLDENPATH  (ucsc)    UCSC human genome annotations and sequences

You can also move precomputed protein alignments to another location
in a similar way. Edit $PPH/config/paths.cnf to reflect the change:

PRECOMPATH  (precomputed)  UniRef100-based multiple sequence alignments

IMPORTANT! - Move or copy each subdirectory as a whole, preserving
its internal tree carefully. PolyPhen-2 relies on a predefined internal
structure for each of its data directories.


* Shared installation

If you want several users on a multiuser system to be able to share
the same PolyPhen-2 installation, you might need to make a few changes
to the default configuration.

First of all, make sure file/directory permissions are set properly,
in order to allow all users read access to the PolyPhen-2 installation
directory and all its subdirectories.

Edit $PPH/config/paths.cnf file and change the following line:

From (default):

SCRATCH = $CONFIG{PPH}/scratch

To:

SCRATCH = $ENV{HOME}/scratch

Alternatively, users can specify a path to their personal scratch
directory via "-d dumpdir" option each time they execute run_pph.pl
command, e.g.:

  $ $PPH/bin/run_pph.pl -d ~/tmp/scratch ...


* Personal / project configuration files

It is possible to create and use several different PolyPhen-2
configurations with the same install. PolyPhen-2 looks for its
configuration directories in several locations in the following
order of preference:

./.pph/       (in the current directory)
~/.pph/       (in the user's home directory)
$PPH/config/  (in the PolyPhen-2 installation directory)

Configuration directory found first will be used. Note, that a complete
set of all configuration files should be present in each alternative
configuration directory and all other configuration sources elsewhere
on the system will be ignored.

To create your own configuration, make a full copy of the system-wide
defaults first:

  $ mkdir ~/.pph
  $ cp $PPH/config/*.cnf ~/.pph/

Now edit configuration files inside ~/.pph/ to match your preferences.
Remember, you need to always copy a complete set of configuration
files to your alternative configuration directory, even if you only
want to change a single configuration option.


* Proteins not in UniProtKB

If you know UniProtKB accession or entry name for your protein then
this is all you need to submit to run_pph.pl, together with the
variant's sequence position and a pair of AA residue codes. If however,
your variants are in some other known protein (e.g., RefSeq or
Ensembl) or you have a novel / unannotated sequence to analyze,
you can still submit it to run_pph.pl, with a little extra effort.

If your protein is from one of the supported "alien" databases, you
can simply use "alien" accession in place of a UniProtKB one. PolyPhen-2
knows about and automatically recognizes protein accessions from the
following databases:

GeneID RefSeq GI PDB GO IPI UniParc PIR UniGene EMBL EMBL-CDS
Ensembl Ensembl_TRS Ensembl_PRO

Note however, that PolyPhen-2 uses cross-reference data from UniProtKB
to translate all non-UniProt identifiers to UniProtKB accessions it
uses internally. These cross-references are ambiguous in many cases:
while the entries in different databases may be related, their
sequences may not be necessarily identical. This would cause sequence
errors posted by PolyPhen-2 because it will not be able to locate
correct residues at the sequence positions specified.

To avoid this problem, or in case you want to analyze new or
unannotated proteins, you may prefer to submit protein sequences
to run_pph.pl, in addition to the input file with the variants
specifications.

Prepare a text file with all your protein sequences in standard
FASTA format. Excerpt from the NCBI BLAST User Guide:

FASTA

A sequence in FASTA format begins with a single-line description,
followed by lines of sequence data. The description line (defline) is
distinguished from the sequence data by a greater-than (">") symbol at
the beginning. It is recommended that all lines of text be shorter
than 80 characters in length. An example sequence in FASTA format is:

  >gi|129295|sp|P01013|OVAX_CHICK GENE X PROTEIN
  QIKDLLVSSSTDLDTTLVLVNAIYFKGMWKTAFNAEDTREMPFHVTKQESKPVQMMCMNNSFNVATLPAE
  KMKILELPFASGDLSMLVLLPDEVSDLERIEKTINFEKLTEWTNPNTMEKRRVKVYLPQMKIEEKYNLTS
  VLMALGMTDLFIPSANLTGISSAESLKISQAVHGAFMELSEDGIEMAGSTGVIEDIKHSPESEQFRADHP
  FLFLIKHNPTNTIVYFGRYWSP
  >gi|6754226|ref|NP_034580.1| homeobox protein Hox-A11
  MMDFDERGPCSSNMYLPSCTYYVSGPDFSSLPSFLPQTPSSRPMTYSYSSNLPQVQPVREVTFREYAIEP
  ATKWHPRGNLAHCYSAEELVHRDCLQAPSAAGVPGDVLAKSSANVYHHPTPAVSSNFYSTVGRNGVLPQA
  FDQFFETAYGTPENLASSDYPGDKNAEKGPQAAAATSAAAVAAAATGAPATSSSDGGGGGGCQEAAAEEK
  ERRRRPESSSSPESSSGHTEDKAGGSGGQRTRKKRCPYTKYQIRELEREFFFSVYINKEKRLQLSRMLNL
  TDRQVKIWFQNRRMKEKKINRDRLQYYSANPLL

Blank lines are not allowed in the middle of FASTA input.

Sequences are expected to be represented in the standard IUB/IUPAC
amino acid and nucleic acid codes, with these exceptions: lower-case
letters are accepted and are mapped into upper-case; a single hyphen
or dash can be used to represent a gap of indeterminate length;
and in amino acid sequences, U and * are acceptable letters.

If you are preparing FASTA file manually, you can use simplified
version of FASTA identifiers:

  >P01013
  QIKDLLVSSSTDLDTTLVLVNAIYFKGMWKTAFNAEDTREMPFHVTKQESKPVQMMCMNNSFNVATLPAE
  KMKILELPFASGDLSMLVLLPDEVSDLERIEKTINFEKLTEWTNPNTMEKRRVKVYLPQMKIEEKYNLTS
  ...
  >NP_034580
  MMDFDERGPCSSNMYLPSCTYYVSGPDFSSLPSFLPQTPSSRPMTYSYSSNLPQVQPVREVTFREYAIEP
  ATKWHPRGNLAHCYSAEELVHRDCLQAPSAAGVPGDVLAKSSANVYHHPTPAVSSNFYSTVGRNGVLPQA
  ...

The only mandatory rule is that identifiers entered after ">" symbol
should be unique strings without embedded blanks in them.

IMPORTANT! - Never use standard UniProtKB accessions or entry names
as identifiers for non-UniProtKB sequences in your FASTA files.
UniProtKB identifiers are used internally by PolyPhen-2 to access
canonical UniProtKB sequences in the built-in database. If you edit
a UniProtKB sequence, remember to always change the accession in its
definition line, e.g., by appending a unique version string:

>P01013.X10

Prepare input file for run_pph.pl using protein identifiers matching
the primary accessions from your FASTA file. Note, PolyPhen-2 always
ignores "gi" accession numbers present in GenBank FASTA deflines, so
the primary accessions for two proteins listed above would be P01013
and NP_034580.1, and the input file would look like this:

P01013     5 L A
P01013    10 S F
NP_034580 15 Y P
NP_034580 25 G R
...

Now submit both files to run_pph.pl program using "-s seqfile.fa"
command-line option:

  $ $PPH/bin/run_pph.pl -s myproteins.fa myvariants.input

Where "myproteins.fa" is the file with your sequences in FASTA format
and "myvariants.input" is input file with the variants specified using
unique protein identifiers matching the ones in "myproteins.fa".

Note, that analyzing novel proteins may involve building multiple
sequence alignments. This takes plenty of computational resources
and CPU time if the number of proteins is sufficient. Consider running
run_pph.pl in parallel mode on a multi-CPU server or cluster
(see * Parallel execution support for details).


* Parallel execution support

Both mapsnps.pl and run_pph.pl programs have some level of support for
parallel execution built-in. This makes them capable of utilizing
efficiently multi-CPU multi-core computer hardware for processing
very large datasets.

If your computer has a multi-core CPU, you can start multiple instances
of run_pph.pl via this simple Bash (v3) wrapper script:

---cut here---
#!/bin/bash
M=4   # number of program instances to run
for (( N=1; N<=$M; N++ )); do
  $PPH/bin/run_pph.pl -r $N/$M "$@" 1>pph$N.features 2>pph$N.log &
done
wait
rm -f pph.features pph.log
for (( N=1; N<=$M; N++ )); do
  cat pph$N.features >>pph.features
  cat pph$N.log >>pph.log
  rm -f pph$N.features pph$N.log
done
---cut here---

Copy & save the above code to a file (e.g., "run_pph4.sh"), set executable
bit on it and run it in the background, e.g.:

  $ chmod +x run_pph4.sh
  $ ./run_pph4.sh -d ~/tmp/scratch $PPH/sets/test.input >run_pph4.log 2>&1 &

This will create "pph.features" output file identical to
$PPH/sets/test.pph.output except it will take approximately 1/4th
of a time single process would take on the same quad-core computer.

If you have PolyPhen-2 installed on a Linux cluster with one of Grid
Engine or Platform LSF distributed execution environment management
systems, you can submit multiple instances of run_pph.pl or mapsnps.pl
without any additional scripts, simply as standard array jobs. Both
programs will recognize they are running on a cluster in array mode
and split the input file automatically, processing it in parallel.

Submitting a Grid Engine array job:

  $ qsub -cwd -b y -N pph -t 1-16 $PPH/bin/run_pph.pl pph.input

Submitting a Platform LSF array job:

  $ bsub -cwd `pwd` -J 'pph[1-16]' -o pph.o%J.%I -e pph.e%J.%I $PPH/bin/run_pph.pl pph.input

Both examples will submit 16 instances of run_pph.pl to a default
cluster queue. Results will be written to files named by appending
job ID and sequential task number to the job name ("pph"). You will
then have to collect results manually, e.g.:

  $ cat pph.o*.{1..16} >pph.features
  $ cat pph.e*.{1..16} >pph.log

Note: You may need to enable PATH environment variable adjustment
configuration option for cluster jobs by uncommenting the following
line in your $PPH/config/paths.cnf file:

GRID_PATH = /bin:/usr/bin:/usr/java/latest/bin:/usr/local/bin

Edit the PATH directories search list to match your cluster's
configuration.


* Analyzing reciprocal substitutions (EXPERIMENTAL)

Conservation scores PolyPhen-2 computes are directional, i.e., they
depend on the direction of substitution. PolyPhen-2 will check amino
acid residues in user input (AA1 and AA2) against reference residue
found in the query protein sequence at the position of substitution
to make sure AA1 matches the reference AA, so that the observed change
follows the rule:

  (AA1 == query AA) -> AA2

If PolyPhen-2 finds instead that AA2 in the user input matches a
reference AA, it will swap the two user-submitted residues before
calculating scores, to force AA1 to always match query sequence.
A warning message will be posted in such cases, e.g.:

  WARNING: Swapped input residues AA1 (V) and AA2 (M) for P12259 query sequence at position (1764)

This is done as an attempt to automatically correct putatively
polymorphic sites in user input assuming that the query sequence
always has a correct reference / ancestral state. This is mostly
true for Swiss-Prot "canonical" entry sequences but may not be
the case for other proteins, especially user-submitted sequences.

This behavior can be disabled by editing $PPH/options.cnf file and
disabling SWAPRESIDUES option by changing it from 1 (default) to 0:

SWAPRESIDUES = 0

When SWAPRESIDUES option is disabled, all variants where AA1 residue
does not match reference sequence will be reported as fatal input
errors and their processing will be skipped.

However, in some specific cases you may want to analyze variants
assuming they have actually occurred in reciprocal direction:

  AA1 -> (AA2 == query AA)

One such example would be analyzing substitutions that occurred in
human lineage since split from a close sister species (e.g. chimp).
Here, AA1 would be a reconstructed common ancestral state residue
and AA2 is a variant fixed in humans. To enable the reciprocal mode,
you will need to change REVERSEDIRECTION option in $PPH/options.cnf:

REVERSEDIRECTION = 1

Note, that while in reciprocal mode, PolyPhen-2 will still use multiple
sequence alignments created with human protein sequences as queries
for all its conservation scores inference. It will NOT attempt to
reconstruct a proper common ancestor sequence to use it for homology
searches and MSA building. In practice however, the difference in
alignments for close enough sister sequences should be insignificant.


* Analyzing variants in other species (EXPERIMENTAL)

While PolyPhen-2 evolutionary models were trained on human proteins,
it is quite plausible to assume they should work for other mammals
as well, and perhaps even across other species, at least to some
extent. HumDiv model in particular, does not incorporate any
population-specific information and can be applied to classify
variants in proteins from other species besides humans.

Note however, that all prediction confidence scores (FPR, TPR, FDR)
are calculated for models trained on human-derived data and will no
longer be reliable when used with mutations in other species.

PolyPhen-2 has some experimental support for analyzing variants in
other species built-in. This is the list of supported species common
names (besides human):

  orangutan
  mouse
  rat
  dog
  zebrafish
  fruitfly

Some broader taxonomic groups of species are also supported, based
on UniProtKB set of taxonomic divisions, e.g.:

  bacteria

For a full list please see:

  ftp://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/taxonomic_divisions/

Setup instructions:

(1) Install and configure PolyPhen-2 following standard procedure
described in INSTALL file. You can skip downloading and installing
MLC and MultiZ multiple alignments. If you already have MLC alignments
installed into $PPH/precomputed directory you need to delete or rename
the directory and replace it with an empty stub tree instead:

  $ cd $PPH
  $ mv precomputed/ precomputed.human.bak
  $ mkdir precomputed
  $ cd precomputed
  $ mkdir alignments blastfiles lock profiles structures
  $ cd ..

(2) Make sure to remove all previously generated files stored under
$PPH/scratch/ tree:

  $ find $PPH/scratch -depth -type f -delete

(3) Download and prepare extra annotation and sequence databases for
your species of interest:

  $ cd $PPH/uniprot
  $ $PPH/update/uniprot.pl -n mouse
  $ $PPH/update/unipfam.pl -n mouse

(4) Edit $PPH/options.cnf file and enter correct common and scientific
species names for the following options, e.g.:

REFORGANISM  = Mus musculus
REFORGCOMMON = mouse

You can leave scientific name empty if not applicable:

REFORGANISM  =

(5) Also in $PPH/options.cnf file, disable MAPGENE option:

MAPGENE = 0

Note, that MapSNPs supports human genome only. Genomic variants from
other species will have to be first mapped to proteins / AA substitutions
by some other tool. For instance, you can use snpEff:

http://snpeff.sourceforge.net/

After you convert missense mutations to protein substitutions, format
them according to PolyPhen-2 input format specification and submit to
run_pph.pl. New set of multiple sequence alignments will be build
automatically. Note, building MSA for your species from scratch may
require plenty of computational resources if you want to analyze
variants in a large number of proteins. Consider running run_pph.pl
in parallel mode on a multi-CPU server or cluster (see * Parallel
execution support for details).

After obtaining run_pph.pl annotations for the variants, you can run
PolyPhen-2 classifier with default HumDiv model in the usual way,
e.g.:

  $ $PPH/run_weka.pl mouse.pph.features >mouse.predictions


--------------------------------------------------------------
Author:         Ivan Adzhubey <iadzhubey@rics.bwh.harvard.edu>
Last modified:  Tue Feb 14 00:42:14 EST 2012
--------------------------------------------------------------
